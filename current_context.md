# Project Context Handoff

## What We're Building

A multi-tenant SaaS platform that uses AI to generate social media threads and articles from user-submitted topics. It performs research, summarisation, and content creation, and can publish to X (Twitter) or Typefully.

---

## Current Phase

**Phase 2: Basic Pipeline â€“ Summary Agent** âœ… COMPLETE

---

## Tech Stack

* Python 3.11+ / FastAPI
* PostgreSQL + SQLAlchemy ORM
* Alembic for migrations
* Celery + Redis for async tasks
* OpenAI / Anthropic API support
* Docker for local and cloud deployment

---

## AI Model Configuration Strategy

We support model overrides on a **per-agent basis**, with fallback to a global default. This is handled in `llm/engine.py` using a `DEFAULT_MODELS` dictionary and `settings` from `config.py`.

### `.env` Example:

```dotenv
OPENAI_MODEL=gpt-4
OPENAI_MODEL_TOPIC_AGENT=gpt-4
OPENAI_MODEL_SUMMARY_AGENT=gpt-4-turbo
OPENAI_MODEL_CONTENT_AGENT=gpt-4-turbo
OPENAI_MODEL_RESEARCH_AGENT=gpt-4-turbo
```

### In `config.py`:

```python
class Settings(BaseSettings):
    ...
    openai_model: str = "gpt-4"
    openai_model_topic_agent: str = "gpt-4"
    openai_model_summary_agent: str = "gpt-4-turbo"
    openai_model_content_agent: str = "gpt-4-turbo"
    openai_model_research_agent: str = "gpt-4-turbo"
```

---

## File/Folder Structure

```
xPostingAgent-as-a-Service/
â”œâ”€â”€ alembic/                     # Migrations
â”‚   â”œâ”€â”€ versions/               # Autogenerated migration files
â”‚   â””â”€â”€ env.py                  # Alembic config
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI app entrypoint
â”‚   â”œâ”€â”€ config.py               # Loads settings from .env
â”‚   â”œâ”€â”€ database.py             # DB engine, session factory
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ users.py            # User table
â”‚   â”‚   â”œâ”€â”€ requests.py         # Request table
â”‚   â”‚   â”œâ”€â”€ research_sources.py # Source metadata per request
â”‚   â”‚   â””â”€â”€ summaries.py        # âœ… NEW: Stores combined summary + key points
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ research_agent.py   # Research Agent: suggests + verifies sources
â”‚   â”‚   â””â”€â”€ summary_agent.py    # âœ… NEW: Summarises research into summary + key points
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ research_prompt.py  # Prompt builder for research agent
â”‚   â”‚   â””â”€â”€ summary_prompt.py   # âœ… NEW: Prompt builder for summary agent
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ engine.py           # Handles GPT calls with agent-aware model lookup
â”œâ”€â”€ insert_dummy_data.py        # Script to insert test user/request
â”œâ”€â”€ test_run_research_agent.py  # Manual test for the research agent
â”œâ”€â”€ app/tests/
â”‚   â””â”€â”€ test_run_summary_agent.py # âœ… NEW: Manual test for the summary agent
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
```

---

## Defined Classes and Functions

### `app/config.py`

* `Settings(BaseSettings)`: Loads environment variables for model config and runtime

  * Includes model overrides per agent (e.g. `openai_model_summary_agent`)

### `app/database.py`

* `engine`: SQLAlchemy DB engine
* `SessionLocal`: Session maker for transactions
* `Base`: SQLAlchemy declarative base

### `app/models/`

#### `research_sources.py`

* `ResearchSource`: SQLAlchemy model for storing:

  * `url`, `title`, `author`, `verification_status`, `relevance_score`, `freshness_score`, `last_verified_at`, `summary`, `key_points`, `is_used`, etc.

#### `summaries.py`

* `Summary`: SQLAlchemy model for storing final summarisation output:

  * `request_id`, `user_id`, `combined_summary`, `combined_key_points`, `source_count`, `is_used`, `created_at`

### `app/llm/engine.py`

* `generate_completion(prompt, model_name=None, agent="default")`

  * Selects model using `DEFAULT_MODELS.get(agent, settings.openai_model)`
  * Prints active model for debugging

### `app/prompts/summary_prompt.py`

* `build_summary_prompt(text, key_points, length_limit, content_type)`:

  * Builds a structured LLM prompt for summarisation using verified source inputs

### `app/agents/summary_agent.py`

* `combine_summaries(sources)`:

  * Combines all source summaries into one text block

* `merge_key_points(sources)`:

  * Deduplicates and merges key points across all verified sources

* `parse_llm_output(response_text)`:

  * Splits LLM response into summary and key points section

* `generate_and_store_summary(request_id, verified_sources, target_length, content_type, user_id)`:

  * Main pipeline that:

    1. Combines summaries
    2. Builds prompt
    3. Calls LLM
    4. Parses result
    5. Saves to `summaries` table

### `insert_dummy_data.py`

* Inserts dummy `User` and `Request` into DB for testing

### `test_run_research_agent.py`

* Manual test runner for `generate_research_sources()` pipeline

### `test_run_summary_agent.py`

* âœ… NEW manual test runner for summary agent
* Inserts dummy request + verified sources with `summary`/`key_points`
* Runs `generate_and_store_summary()` and prints results

---

## Tests

* Manual test scripts:

  * `test_run_research_agent.py`: prints verified research sources
  * `test_run_summary_agent.py`: prints summary + key points generated from sources

---

## Whatâ€™s Next

ğŸ•¸ï¸ In the next phase, we will:

1. Implement the **Content Generation Agent**
2. Take summaries + key points â†’ turn into engaging threads/articles
3. Store output in `content_queue` table for review/posting

---

*Last updated: 2025-06-19*
