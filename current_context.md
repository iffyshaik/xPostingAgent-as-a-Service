# Project Context Handoff

## What We're Building

A multi-tenant SaaS platform that uses AI to generate social media threads and articles from user-submitted topics. It performs research, summarisation, and content creation, and can publish to X (Twitter) or Typefully.

---

## Current Phase

**Phase 2: Basic Research Agent** âœ… COMPLETE

---

## Tech Stack

* Python 3.11+ / FastAPI
* PostgreSQL + SQLAlchemy ORM
* Alembic for migrations
* Celery + Redis for async tasks
* OpenAI / Anthropic API support
* Docker for local and cloud deployment

---

## AI Model Configuration Strategy

We support model overrides on a **per-agent basis**, with fallback to a global default. This is handled in `llm/engine.py` using a `DEFAULT_MODELS` dictionary and `settings` from `config.py`.

### `.env` Example:

```dotenv
OPENAI_MODEL=gpt-4
OPENAI_MODEL_TOPIC_AGENT=gpt-4
OPENAI_MODEL_SUMMARY_AGENT=gpt-4-turbo
OPENAI_MODEL_CONTENT_AGENT=gpt-4-turbo
OPENAI_MODEL_RESEARCH_AGENT=gpt-4-turbo
```

### In `config.py`:

```python
class Settings(BaseSettings):
    ...
    openai_model: str = "gpt-4"
    openai_model_topic_agent: str = "gpt-4"
    openai_model_summary_agent: str = "gpt-4-turbo"
    openai_model_content_agent: str = "gpt-4-turbo"
    openai_model_research_agent: str = "gpt-4-turbo"
```

---

## File/Folder Structure

```
xPostingAgent-as-a-Service/
â”œâ”€â”€ alembic/                     # Migrations
â”‚   â”œâ”€â”€ versions/               # Autogenerated migration files
â”‚   â””â”€â”€ env.py                  # Alembic config
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI app entrypoint
â”‚   â”œâ”€â”€ config.py               # Loads settings from .env
â”‚   â”œâ”€â”€ database.py             # DB engine, session factory
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ users.py            # User table
â”‚   â”‚   â”œâ”€â”€ requests.py         # Request table
â”‚   â”‚   â””â”€â”€ research_sources.py # âœ… NEW: Source metadata per request
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ research_agent.py   # âœ… NEW: Suggests and verifies sources
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â””â”€â”€ research_prompt.py  # âœ… NEW: Prompt builder for research agent
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ engine.py           # Handles GPT calls with agent-aware model lookup
â”œâ”€â”€ insert_dummy_data.py        # âœ… Script to insert test user/request
â”œâ”€â”€ test_run_research_agent.py  # âœ… Script to test the research agent manually
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
```

---

## Defined Classes and Functions

### `app/config.py`

* `Settings(BaseSettings)`: Loads environment variables for model config and runtime.
* Adds support for: `openai_model_research_agent`

### `app/database.py`

* `engine`: SQLAlchemy DB engine
* `SessionLocal`: Session maker for transactions
* `Base`: SQLAlchemy declarative base

### `app/models/`

#### `research_sources.py`

* `ResearchSource`: SQLAlchemy model for storing source metadata:

  * `url`, `title`, `author`, `verification_status`, `relevance_score`, `freshness_score`, `last_verified_at`, etc.
  * Linked to both `requests` and `users`

### `app/llm/engine.py`

* `generate_completion(prompt, model_name=None, agent="default")`:

  * Selects model using `DEFAULT_MODELS.get(agent, settings.openai_model)`
  * Prints which model is being used for debugging

### `app/prompts/research_prompt.py`

* `build_research_prompt(topic, preference)`:

  * Constructs a system prompt instructing GPT to return a list of articles in the form: `[Title] by [Author] - [URL]`

### `app/agents/research_agent.py`

* `generate_research_sources(request_id, content_topic, user_id, limit=5, preference='balanced')`:

  * Coordinates AI prompt, parsing, verification, and DB storage
  * Skips duplicates and logs actions
  * Adds placeholder scores for relevance/freshness
* `parse_ai_response(response_text)`:

  * Parses each `1. [Title] by [Author] - [URL]` line into a dictionary
* `verify_url(url)`:

  * Uses `requests.head()` (fallback to `get()`) with a browser-like `User-Agent` to validate link

### `insert_dummy_data.py`

* Inserts a `User` and `Request` into the database for test purposes

### `test_run_research_agent.py`

* Runs the full `generate_research_sources()` pipeline and prints inserted sources from DB

---

## Tests

* Manual test script `test_run_research_agent.py`:

  * Runs the agent using a test request ID
  * Prints parsed sources, verified count, and database entries

---

## Whatâ€™s Next

ðŸ”œ In the next phase, we will:

1. Implement the **Summary Agent**
2. For each verified source, fetch and summarise content
3. Extract key points and store results in `summaries` table

---

*Last updated: 2025-06-19*
