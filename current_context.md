# ğŸ§  xPostingAgent-as-a-Service â€” Current Context

This document captures the full current state of the codebase, to ensure any developer can continue work without losing context. **Update this file after each major dev session.**

---

## ğŸ“ Project Folder Structure (as of 2025-06-20)

```
xPostingAgent-as-a-Service/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ users.py
â”‚   â”‚   â”œâ”€â”€ requests.py
â”‚   â”‚   â”œâ”€â”€ research_sources.py
â”‚   â”‚   â”œâ”€â”€ topic_source_usage.py  âœ… NEW
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ topic_agent.py
â”‚   â”‚   â”œâ”€â”€ research_agent.py      âœ… UPDATED
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ google_search.py       âœ… NEW
â”‚   â”‚   â”œâ”€â”€ ai_source_discovery.py âœ… NEW
â”‚   â”‚   â”œâ”€â”€ source_verification.py âœ… NEW
â”‚   â”‚   â”œâ”€â”€ embedding_similarity.pyâœ… NEW
â”‚   â”‚   â”œâ”€â”€ source_reuse.py        âœ… NEW
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ hash.py                âœ… NEW
â”‚
â”œâ”€â”€ app/tests/
â”‚   â”œâ”€â”€ test_topic_agent.py
â”‚   â”œâ”€â”€ test_topic_source_usage.py     âœ… NEW
â”‚   â”œâ”€â”€ test_run_research_agent.py     âœ… NEW
â”‚
â”œâ”€â”€ alembic/
â”‚   â””â”€â”€ versions/
â”‚       â””â”€â”€ <... autogenerated migrations ...>
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ current_context.md
```

---

## ğŸ§  Agent Layer

### `agents/topic_agent.py`
- **`generate_refined_topic()`**: Uses GPT to refine the original topic into a more specific content topic. Saves result into `requests.content_topic`.

### `agents/research_agent.py`
- **`generate_research_sources()`**: End-to-end agent that:
  1. Fetches sources from both AI and Google
  2. Deduplicates by URL
  3. Verifies URLs and extracts metadata
  4. Filters by relevance using GPT + embedding similarity
  5. Saves valid sources to `research_sources`
  6. Logs access errors and overuse via `topic_source_usage`

---

## ğŸ”§ Services Layer

### `services/google_search.py`
- **`get_google_search_results(topic: str, limit: int)`**  
  Searches using Google Custom Search API and returns a list of article dicts.

### `services/ai_source_discovery.py`
- **`discover_sources_with_ai(topic, limit, preference)`**  
  Prompts the LLM to suggest relevant sources, parsed into `[title, author, url]`.

### `services/source_verification.py`
- **`is_url_accessible(url) â†’ (bool, reason)`** âœ… UPDATED  
  Uses `requests.get()` with user-agent to simulate browser. Logs and returns reason.

- **`extract_page_metadata(url)`**  
  Extracts title/snippet with BeautifulSoup.

- **`check_relevance_with_ai(snippet, topic)`**  
  Uses GPT to verify if the page content is topically aligned.

### `services/embedding_similarity.py`
- **`calculate_embedding_similarity(topic, snippet)`**  
  Embeds both texts using OpenAI Embeddings API and computes cosine similarity.

### `services/source_reuse.py`
- **`is_source_overused(user_id, topic, url)`**  
  Checks if this source was used too many times for a topic by this user.

- **`increment_source_usage(user_id, topic, url)`**  
  Adds or updates a row in `topic_source_usage` for reuse tracking.

---

## ğŸ” `utils/hash.py`
- **`hash_string_sha256(string)`**  
  Returns SHA256 hash of a string â€” used to anonymise topics and URLs for reuse tracking.

---

## ğŸ§ª Tests

### `tests/test_topic_source_usage.py`
- Unit test to verify insertion and reuse incrementing in `topic_source_usage`.

### `tests/test_run_research_agent.py`
- Manual integration test for running the full `generate_research_sources()` pipeline.

---

## ğŸ§¬ Models

### `models/users.py`
```python
id
email
password_hash
subscription_tier
api_quota_daily / api_quota_used_today
created_at / updated_at
```

### `models/requests.py`
```python
id
user_id â†’ FK to users
original_topic
content_topic
status
content_type
auto_post
source_count_limit
platform
...
```

### `models/research_sources.py`
```python
id
request_id â†’ FK
user_id â†’ FK
source_type = "AI Discovery" | "Google Search"
url, title, author
verification_status = "verified" | "failed"
relevance_score
access_status âœ… NEW
verification_attempts
last_verified_at
```

### `models/topic_source_usage.py` âœ… NEW
```python
id
user_id â†’ FK
content_topic_hash
source_url_hash
usage_count
last_used_at
```

---

## ğŸ¤– LLM Model Configuration

- All LLM completions go through:
  ```python
  generate_completion(prompt: str, model_name: str = None, agent: str = "default")
  ```

- Model defaults are set in `config.py` via environment variables:
  ```
  DEFAULT_PROVIDER=openai
  OPENAI_API_KEY=...
  OPENAI_MODEL=gpt-4.1
  ```

- Agent-specific defaults can override global defaults using:
  ```python
  DEFAULT_MODELS = {
      "topic_agent": "gpt-4.1",
      "research_agent": "gpt-4.1",
      ...
  }
  ```

---

## ğŸ› ï¸ Developer Notes

### ğŸ“Œ How to Add New Model Columns
- Add to the model class
- Run:
  ```bash
  alembic revision --autogenerate -m "add column"
  alembic upgrade head
  ```
- Safe: old rows will get `NULL` unless `nullable=False`

---

## ğŸ” Known TODOs / Future Tasks

- Add summary + key points generation into `summaries` table
- Implement thread generation logic for X (Twitter)
- Build admin panel to inspect sources, errors, overused domains
- Integrate logging for LLM costs
- Write tests for all new service modules

---

âœ… You are now fully up to date as of 2025-06-20.
