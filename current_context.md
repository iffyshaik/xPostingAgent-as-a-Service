# 🧠 xPostingAgent-as-a-Service — Current Context

This document captures the full current state of the codebase, to ensure any developer can continue work without losing context. **Update this file after each major dev session.**

---

## 📁 Project Folder Structure (as of 2025-06-20)

```
xPostingAgent-as-a-Service/
│
├── app/
│   ├── main.py
│   ├── config.py
│   ├── database.py
│   ├── models/
│   │   ├── users.py
│   │   ├── requests.py
│   │   ├── research_sources.py
│   │   ├── topic_source_usage.py  ✅ NEW
│   ├── agents/
│   │   ├── topic_agent.py
│   │   ├── research_agent.py      ✅ UPDATED
│   ├── services/
│   │   ├── google_search.py       ✅ NEW
│   │   ├── ai_source_discovery.py ✅ NEW
│   │   ├── source_verification.py ✅ NEW
│   │   ├── embedding_similarity.py✅ NEW
│   │   ├── source_reuse.py        ✅ NEW
│   ├── utils/
│   │   ├── hash.py                ✅ NEW
│
├── app/tests/
│   ├── test_topic_agent.py
│   ├── test_topic_source_usage.py     ✅ NEW
│   ├── test_run_research_agent.py     ✅ NEW
│
├── alembic/
│   └── versions/
│       └── <... autogenerated migrations ...>
│
├── .env
├── requirements.txt
└── current_context.md
```

---

## 🧠 Agent Layer

### `agents/topic_agent.py`
- **`generate_refined_topic()`**: Uses GPT to refine the original topic into a more specific content topic. Saves result into `requests.content_topic`.

### `agents/research_agent.py`
- **`generate_research_sources()`**: End-to-end agent that:
  1. Fetches sources from both AI and Google
  2. Deduplicates by URL
  3. Verifies URLs and extracts metadata
  4. Filters by relevance using GPT + embedding similarity
  5. Saves valid sources to `research_sources`
  6. Logs access errors and overuse via `topic_source_usage`

---

## 🔧 Services Layer

### `services/google_search.py`
- **`get_google_search_results(topic: str, limit: int)`**  
  Searches using Google Custom Search API and returns a list of article dicts.

### `services/ai_source_discovery.py`
- **`discover_sources_with_ai(topic, limit, preference)`**  
  Prompts the LLM to suggest relevant sources, parsed into `[title, author, url]`.

### `services/source_verification.py`
- **`is_url_accessible(url) → (bool, reason)`** ✅ UPDATED  
  Uses `requests.get()` with user-agent to simulate browser. Logs and returns reason.

- **`extract_page_metadata(url)`**  
  Extracts title/snippet with BeautifulSoup.

- **`check_relevance_with_ai(snippet, topic)`**  
  Uses GPT to verify if the page content is topically aligned.

### `services/embedding_similarity.py`
- **`calculate_embedding_similarity(topic, snippet)`**  
  Embeds both texts using OpenAI Embeddings API and computes cosine similarity.

### `services/source_reuse.py`
- **`is_source_overused(user_id, topic, url)`**  
  Checks if this source was used too many times for a topic by this user.

- **`increment_source_usage(user_id, topic, url)`**  
  Adds or updates a row in `topic_source_usage` for reuse tracking.

---

## 🔐 `utils/hash.py`
- **`hash_string_sha256(string)`**  
  Returns SHA256 hash of a string — used to anonymise topics and URLs for reuse tracking.

---

## 🧪 Tests

### `tests/test_topic_source_usage.py`
- Unit test to verify insertion and reuse incrementing in `topic_source_usage`.

### `tests/test_run_research_agent.py`
- Manual integration test for running the full `generate_research_sources()` pipeline.

---

## 🧬 Models

### `models/users.py`
```python
id
email
password_hash
subscription_tier
api_quota_daily / api_quota_used_today
created_at / updated_at
```

### `models/requests.py`
```python
id
user_id → FK to users
original_topic
content_topic
status
content_type
auto_post
source_count_limit
platform
...
```

### `models/research_sources.py`
```python
id
request_id → FK
user_id → FK
source_type = "AI Discovery" | "Google Search"
url, title, author
verification_status = "verified" | "failed"
relevance_score
access_status ✅ NEW
verification_attempts
last_verified_at
```

### `models/topic_source_usage.py` ✅ NEW
```python
id
user_id → FK
content_topic_hash
source_url_hash
usage_count
last_used_at
```

---

## 🤖 LLM Model Configuration

- All LLM completions go through:
  ```python
  generate_completion(prompt: str, model_name: str = None, agent: str = "default")
  ```

- Model defaults are set in `config.py` via environment variables:
  ```
  DEFAULT_PROVIDER=openai
  OPENAI_API_KEY=...
  OPENAI_MODEL=gpt-4.1
  ```

- Agent-specific defaults can override global defaults using:
  ```python
  DEFAULT_MODELS = {
      "topic_agent": "gpt-4.1",
      "research_agent": "gpt-4.1",
      ...
  }
  ```

---

## 🛠️ Developer Notes

### 📌 How to Add New Model Columns
- Add to the model class
- Run:
  ```bash
  alembic revision --autogenerate -m "add column"
  alembic upgrade head
  ```
- Safe: old rows will get `NULL` unless `nullable=False`

---

## 🔍 Known TODOs / Future Tasks

- Add summary + key points generation into `summaries` table
- Implement thread generation logic for X (Twitter)
- Build admin panel to inspect sources, errors, overused domains
- Integrate logging for LLM costs
- Write tests for all new service modules

---

✅ You are now fully up to date as of 2025-06-20.
